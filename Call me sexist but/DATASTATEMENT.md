# Data Statement for "Call Me Sexist But.."

Data set name: The 'Call me sexist but' Dataset (CMSB)
[https://doi.org/10.7802/2251](https://doi.org/10.7802/2251)

Citation (if available): 
Samory, Mattia, Indira Sen(+), Julian Kohne(+), Fabian Floeck, and Claudia Wagner. ""Call me sexist but...": Revisiting Sexism Detection Using Psychological Scales and Adversarial Samples." ICWSM (2021). 
(+Indira Sen and Julian Kohne contributed equally to this work)

Data set developer(s): Mattia Samory, Indira Sen, Julian Kohne, Fabian Floeck, Claudia Wagner

Data statement author(s): Indira Sen and Mattia Samory 

Others who contributed to this document: Julian Kohne and Fabian Floeck

## A. CURATION RATIONALE 

This dataset consists of three types of 'short-text' content: 

1. social media posts (tweets)
2. psychological survey items, and 
3. synthetic adversarial modifications of the former two categories. 

The tweet data can be further divided into 3 separate datasets based on their source: 

1.1 the hostile sexism dataset, 
1.2 the benevolent sexism dataset, and 
1.3 the callme sexism dataset. 


1.1 and 1.2 are pre-existing datasets; refer to section I. PROVENANCE APPENDIX for more information. The rationale for including these dataset specifically is that they feature a variety of sexist expressions in real conversational (social media) settings. In particular, they feature expressions that range from overtly antagonizing the minority gender through negative stereotypes (1.1) to leveraging positive stereotypes to subtly dismiss it as less-capable and fragile (1.2).

The callme sexism dataset (1.3) was collected by us based on the presence of the phrase 'call me sexist but' in tweets. The rationale behind this choice of query was that several Twitter users opine potentially sexist comments and signal so using the presence of this phrase, which arguably serves as a disclaimer for sexist opinions. 

The survey items (2) pertain to attitudinal surveys that are designed to measure sexist attitudes and gender bias in participants. We provide a detailed account of our selection procedure in our paper (see I. PROVENANCE APPENDIX).

Finally, the adversarial examples are generated by crowdworkers from Amazon Mechanical Turk by making minimal changes to tweets and scale items, in order to change sexist examples to non-sexist ones. We hope that these examples will help us control for typical confounds in non-sexist data (e.g., topic, civility) and lead to datasets with fewer biases, and consequently allow us to train more robust machine learning models. We only asked to turn sexist examples into non-sexist ones, and not vice versa, for ethical reasons.

The dataset is annotated to capture cases where text is sexist because of its content (what the speaker believes) or its phrasing (the speaker's choice of words). We explain the rationale for this codebook in our paper (see I. PROVENANCE APPENDIX).

In short, a message may be sexist because of its content---in other words, because of what the speaker believes. For example, the speaker may express stereotypes (how genders are traditionally seen and compared to each other) and behavioral expectations (how individuals of a gender should behave according to traditional views). Also, the speaker may express sexist attitudes towards the inequality that exists between genders, either recognizing and endorsing it, or antagonizing it by denying that the inequality exists or rejecting efforts to combat it.

Moreover, a message may be sexist because of how the speaker phrases it---independently from what the speaker believes. A message is sexist, for example, when it contains attacks, foul language, or derogatory depictions directed towards individuals because of their gender.

## B. LANGUAGE VARIETY/VARIETIES

* BCP-47 language tag: presumably, en-US
* Language variety description: predominantly white-aligned English

## C. SPEAKER DEMOGRAPHIC

The speakers in the social media posts datasets (1) are or were Twitter users. We do not solicit or infer the demographics of these speakers.

The speakers of the psychological survey items dataset (2) are sociology or psychology researchers. While we do not infer the demographics of these speakers, they are typically listed as the authors of the publications accompanying the scales.

The synthetic adversarial modifications dataset (3) contains alterations of texts taken from the former two datasets. Therefore it may carry the characteristics of the original speakers, as well as those of the crowdworkers who produced the modifications. As for the first dataset, we do not solicit or infer the demographics of these speakers.


## D. ANNOTATOR DEMOGRAPHIC

* Description: Amazon mechanical turk workers based in the US with a rating of or above
* First language(s): English
* Training in linguistics/other relevant discipline: The annotators were trained specifically for the annotation task. On top of the annotation training, they were asked to complete a further training for the modification task. The annotation training described the codes for each of the two annotation categories (sexist content and sexist phrasing---the full list and explanation is available in our paper, see I. PROVENANCE APPENDIX). It provided examples and counter-examples of the annotation task. Finally, it required the annotators to correctly label examples for which the ground truth was known. The annotators could only take the final test for the training once.

The crowdworkers producing modifications were asked to train for the task, on top of passing the training for the annotation task. This second training required them to read instructions on how to change modifications so that:

* the modification added, removed, or edited the minimum number of words
* the modified sentence was still grammatically correct and semantically coherent
* the modification turned the sentence from sexist to non-sexist

After reading the instructions, the crowdworkers were tasked with identifying correctly ground-truth modifications.

We do not collect any other demographics of the annotators.


## E. SPEECH SITUATION

Tweets (1): 

* Description: online on social media
* Time: depends on the corpus, sometime between 2014-2019
* Place: online
* Modality (spoken/signed, written): written
* Scripted/edited vs. spontaneous: spontaneous (social media posts)
* Synchronous vs. asynchronous interaction: asynchronous
* Intended audience: social networks

Psychological scales (2):

* Description: survey scale items
* Time: 1968--2015
* Place: typically administered in academic settings or in private practices
* Modality (spoken/signed, written): written
* Scripted/edited vs. spontaneous: scripted
* Synchronous vs. asynchronous interaction: asynchronous
* Intended audience: general English-speaking population

Adversarial Examples (3):

* Description: synthetic data generated from both social media and survey items, therefore has features of the aforementioned datasets while being entirely scripted, to be used as training and/or test data for machine learning models.


## F. TEXT CHARACTERISTICS

The tweets contained in this dataset (1) cover many different topics and genres such as sports, entertainment and current events. The main defining feature of the data is that it contain explicit and implicit sexist comments, some of which are general while others are targeted towards certain individuals.

The psychological scale items (2) are statements developed as stimuli on which the subjects taking the survey express their agreement on a binary or Likert scale. The items are devised to measure the subjects' attitudes with respect to sexism and related constructs, such as general attitudes towards men or women, egalitarianism, gender and sex role beliefs, stereotypical beliefs about men or women, attitudes towards feminism or gendered norms.

We describe a few common strategies that crowdworkers employed to modify original texts into adversarial examples (3).

## G. RECORDING QUALITY

N/A

## H. OTHER

Data preprocessing is explained in the paper. In addition to those procedures, to safeguard the people in the social media posts and adversarial datasets, as well as to preserve the privacy of crowdworkers, we pseudonymized all @handles and MTurk IDs. Furthermore, we shortened family names in multi-word mentions (e.g., John Doe to John D). We used a semi-automated procedure: we extracted mentions of persons using a NER model; we selected multi-word mentions using a regular expression; we manually excluded mentions that were not of persons; we shortened the last word in the multi-word span using a regular expression.


## I. PROVENANCE APPENDIX

For the original hostile sexism, dataset, see: 
Waseem, Zeerak and Dirk Hovy. (2016). Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter. Proceedings of the NAACL Student Research Workshop, 88–93. [https://www.aclweb.org/anthology/N16-2013.pdf](https://www.aclweb.org/anthology/N16-2013.pdf)


For the original benevolent sexism dataset, see: 
Jha, Akshita and Radhika Mamidi. (2017). When does a compliment become sexist? Analysis and classification of ambivalent sexism using twitter data. Proceedings of the Second Workshop on NLP and Computational Social Science, 7–16. [https://www.aclweb.org/anthology/W17-2902/](https://www.aclweb.org/anthology/W17-2902/)

For the combined dataset described in this data statement, see: 
[https://arxiv.org/abs/2004.12764](https://arxiv.org/abs/2004.12764)


## About this document

A data statement is a characterization of a dataset that provides context to allow developers and users to better understand how experimental results might generalize, how software might be appropriately deployed, and what biases might be reflected in systems built on the software.

Data Statements are from the University of Washington. Contact: [datastatements@uw.edu](mailto:datastatements@uw.edu). This document template is licensed as [CC0](https://creativecommons.org/share-your-work/public-domain/cc0/).

This version of the markdown Data Statement is from June 4th 2020. The Data Statement template is based on worksheets distributed at the [2020 LREC workshop on Data Statements](https://sites.google.com/uw.edu/data-statements-for-nlp/), by Emily M. Bender, Batya Friedman, and Angelina McMillan-Major. Adapted to community Markdown template by Leon Dercyznski.
